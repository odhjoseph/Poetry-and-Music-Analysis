{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "\t'''Read in a file object and return an opened representation of that file'''\n",
    "\twith codecs.open(file_path,'r','utf-8') as f:\n",
    "\t\tfile_contents = \"\".join( f.read())\n",
    "\tf.close()\n",
    "\treturn file_contents\n",
    "def create_stopwords():\n",
    "\t'''Generate stopword list compiled by Ted Underwood'''\n",
    "\twith codecs.open(cwd + \"text_cleaning_resources/underwood_stopwords.txt\",\"r\",\"utf-8\") as stopwords_in:\t\t\n",
    "\t\tstopwords = set(stopwords_in.read().split())\n",
    "\t\treturn stopwords\n",
    "def create_ortho_dict():\n",
    "\t'''Create mapping from spelling variant to controlled representation (orthographically-normalized representation) of word'''\n",
    "\tortho_dict = {}\n",
    "\twith codecs.open(cwd + \"text_cleaning_resources/orthographic_variants.txt\",\"r\",\"utf-8\") as ortho:\n",
    "\t\tortho = ortho.read().replace(\"\\r\",\"\").lower().split(\"\\n\")[:-1]\n",
    "\t\tfor row in ortho:\n",
    "\t\t\tsr = row.split(\"\\t\")\n",
    "\t\t\tortho_dict[ sr[0] ] = sr[1]\n",
    "\treturn ortho_dict\n",
    "def standardize_spelling(w):\n",
    "\t'''Read in a word and return an orthograpically normalized representation of the word'''\n",
    "\ttry:\n",
    "\t\treturn ortho_dict[w]\n",
    "\texcept:\n",
    "\t\treturn w\n",
    "def remove_stopwords(l):\n",
    "\t'''Read in a list of words and return that list sans stopwords'''\n",
    "\treturn [w for w in l if w not in stopwords and len(w) > 1]\n",
    "\t\n",
    "def remove_punctuation(s):\n",
    "\t'''Read in a string and return that strip without any punctuation except the hyphen and en-dash'''\n",
    "\treturn sub(\"[^\\P{P}']+0123456789\", \" \", s)\n",
    "\n",
    "def lemmatize_word(w):\n",
    "\t'''Read in a single word and return it in its lemmatized state'''\n",
    "\treturn lemmatizer.lemmatize(w)\n",
    "def clean_sentence(s):\n",
    "    s = remove_punctuation(s)\n",
    "    words = s.split()\n",
    "    for i in range(len(words)):    \n",
    "        words[i] = standardize_spelling(words[i])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import deque, defaultdict, Counter\n",
    "from itertools import islice, combinations\n",
    "from nltk.util import ngrams\n",
    "from regex import sub\n",
    "from nltk import data\n",
    "from os import path, remove\n",
    "import sys, codecs, operator\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd += '/detect_reuse-master/'\n",
    "stopwords = create_stopwords()\n",
    "ortho_dict = create_ortho_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean1 = clean_sentence(sentence1)\n",
    "clean2 = clean_sentence(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramify(clean):\n",
    "    bigrams = []\n",
    "    for i in range(len(clean) - 1):\n",
    "        bigrams.append((clean[i], clean[i +1]))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigramify(clean):\n",
    "    trigrams = []\n",
    "    for i in range(len(clean) - 2):\n",
    "        trigrams.append((clean[i], clean[i +1], clean[i + 2]))\n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(bigram1, bigram2):\n",
    "    if len(bigram1) == 0:\n",
    "        return 0\n",
    "    if len(bigram2) == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    match = 0\n",
    "    for bi1 in bigram1:\n",
    "        for bi2 in bigram2: \n",
    "            count += 1\n",
    "            if bi1 == bi2: \n",
    "                match += 1\n",
    "    return match/count * (len(bigram1) + len(bigram2))/ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesplit(file):\n",
    "    lines = file.split('\\n')\n",
    "    if '' in lines:\n",
    "        lines.remove('')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalsimiliarity(file1, file2): \n",
    "    try: \n",
    "        poem1 = read_file(file1)\n",
    "        poem2 = read_file(file2)\n",
    "    except: \n",
    "        return False\n",
    "    lines1 = linesplit(poem1)\n",
    "    lines2 = linesplit(poem2)\n",
    "    cleanlines1 = []\n",
    "    for line in lines1:\n",
    "        cleanlines1.append((clean_sentence(line), line))\n",
    "    cleanlines2 = []\n",
    "    for line in lines2:\n",
    "        cleanlines2.append((clean_sentence(line), line))\n",
    "    bigramlist1 = list()\n",
    "    for line in cleanlines1:\n",
    "        clean, l = line\n",
    "        bigramlist1.append((trigramify(clean), l))\n",
    "    bigramlist2 = list()\n",
    "    for line in cleanlines2:\n",
    "        clean, l = line\n",
    "        bigramlist2.append((trigramify(clean), l))\n",
    "    checklist = list()\n",
    "    for gr1 in bigramlist1: \n",
    "        for gr2 in bigramlist2:\n",
    "            g1, r1 = gr1\n",
    "            g2, r2 = gr2\n",
    "            checklist.append((check(g1, g2), r1, r2))\n",
    "    t = 0\n",
    "    c = 0\n",
    "    for x in checklist: \n",
    "        i,j,k = x\n",
    "        t += i\n",
    "        c += 1\n",
    "    return t/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = list()\n",
    "for gr1 in bigramlist1: \n",
    "    for gr2 in bigramlist2:\n",
    "        g1, r1 = gr1\n",
    "        g2, r2 = gr2\n",
    "        checklist.append((check(g1, g1), r1, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/longbrake/Songs_Poetry/3885.txt'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-6b4a8d64e703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleanlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mbigramlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigramify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigramlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-554c57a6e4df>\u001b[0m in \u001b[0;36mtrigramify\u001b[0;34m(clean)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrigrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt = list()\n",
    "for file in data: \n",
    "    try: \n",
    "        poem = read_file(file)\n",
    "    except: \n",
    "        continue\n",
    "    lines = linesplit(poem)\n",
    "    cleanlines = []\n",
    "    for line in lines:\n",
    "        cleanlines.append((clean_sentence(line), line))\n",
    "    bigramlist = list()\n",
    "    for line in cleanlines:\n",
    "        clean, l = line\n",
    "        bigramlist.append(trigramify(clean))\n",
    "    dt.append((bigramlist, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "for root, dirs, files in os.walk('/Users/longbrake/Songs_Poetry'):\n",
    "    for file in files: \n",
    "        data.append(root + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlist = list()\n",
    "chlist = dict()\n",
    "for i in range(len(dt[:-1])):\n",
    "    f1, fa1 = dt[i]\n",
    "    for f2 in dt[i + 1:]:\n",
    "        checklist = list()\n",
    "        f2, fa2 = f2\n",
    "        checklist.append((check(f1, f2), gr1, gr2))\n",
    "        t = 0\n",
    "        c = 0\n",
    "        for x in checklist: \n",
    "            i,j, k = x\n",
    "            c += i\n",
    "            t += 1\n",
    "        chlist[(fa1, fa2)] = checklist\n",
    "        simlist.append((t/c, fa1, fa2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chlist: \n",
    "    if ch[1] == '/Users/longbrake/Songs_Poetry/6728.txt':\n",
    "        if ch[2] == '/Users/longbrake/Songs_Poetry/2980.txt':\n",
    "            top = ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramlist = list()\n",
    "for file1 in data\n",
    "    try: \n",
    "        poem1 = read_file(file1)\n",
    "    except: \n",
    "        return False\n",
    "    lines1 = linesplit(poem1)\n",
    "    cleanlines1 = []\n",
    "    for line in lines1:\n",
    "        cleanlines1.append((clean_sentence(line), line))\n",
    "    bigramlist1 = list()\n",
    "    for line in cleanlines1:\n",
    "        clean, l = line\n",
    "        bigramlist1.append((trigramify(clean), l))\n",
    "    trigramlist.append(bigramlist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(Ahh) \\n When I was young \\n It seemed that life was so wonderful \\n A miracle \\n Oh, it was beautiful, magical \\n And all the birds in the trees \\n Well, they'd be singing so happily \\n Oh, joyfully \\n Oh, playfully watching me \\n But then they sent me away \\n To teach me how to be sensible \\n Logical \\n Oh, responsible, practical \\n And then they showed me a world \\n Where I could be so dependable \\n Oh, clinical \\n Oh, intellectual, cynical \\n There are times when all the world's asleep \\n The questions run too deep \\n For such a simple man \\n Won't you please, please tell me what we've learned? \\n I know it sounds absurd \\n Please tell me who I am \\n I say, now watch what you say \\n Or they'll be calling you a radical \\n A liberal \\n Oh, fanatical, criminal \\n Oh, won't you sign up your name? \\n We'd like to feel you're acceptable \\n Respectable \\n Oh, presentable, a vegetable \\n Take it, take it, take it, yeah \\n But at night when all the world's asleep \\n The questions run so deep \\n Won't you please (Won't you tell me, won't you tell me what we've learned?) \\n Please tell me what we've learned? (Can you hear me? I know it sounds absurd) \\n I know it sounds absurd (Won't you help me? Tell me who I am) \\n But please tell me who I am \\n Who I am \\n Who I am, yeah \\n 'Cause I'm feeling so logical \\n D-d-d-d-d-d-d-digital \\n Yeah, one, two, three, five \\n Ooh, uh, uh, uh, yeah \\n Ooh, it's getting unbelievable \\n \""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file('/Users/longbrake/Songs_Poetry/2980.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Everybody talkin' 'bout the seventh son In the whole wide world there is only one And I'm the one, I'm the one I'm the one, I'm the one The one they call the seventh son I can tell your future, it will come to pass I can do things to you make your heart feel glad Look in the sky, predict the rain Tell when a woman's got another man I'm the one, oh, I'm the one I can talk these words that will sound so sweet They will even make your little heart skip a beat Heal the sick, raise the dead Make the little girls talk outta their heads And make the little girls talk outta their heads I'm the one, hey, hey I'm the one Oh, I'm the one, babe Ooh, I'm the one\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file('/Users/longbrake/Songs_Poetry/3929.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check([('I', 'love', 'Lucy'), ('Lucy', 'loves', 'me')], [('Lucy', 'loves', 'me'), ('I', 'hate', 'you')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's gettin' so lonely inside this bed \\n Don't know if I should lick my wounds  \\n Or say woe is me instead \\n There's an achin' inside my head \\n It's tellin' me I'm better off alone \\n But after midnight morning will come \\n And the day will see  \\n If you will get some \\n They say that girl you know she act too tough, tough, tough \\n Well it's till I turn off the light, turn off the light \\n They say that girl you know she act so rough, rough, rough \\n And I say follow me, follow me, follow me down, down, down, down \\n 'Til you see all my dreams \\n Not everything in this magical world is quite what it seems \\n I looked above the other day \\n Cuz I think I am good and ready for a change \\n I live my life by the moon \\n If it's high play it low, if it's harvest go slow and if it's full, then go \\n Yeah, if you're gonna get some \\n They say that girl you know she act too tough tough tough \\n They say that girl you know she act so rough rough rough \\n I'm searching for things that I just cannot see \\n Why don't you, don't you, don't you, come and be with me \\n I pretend to be cool with me, wanna belive \\n I can do it on my own without my heart on my sleeve \\n I'm running, I'm running, catch up with me life \\n Where is the love that I'm lookin' to find \\n It's all in me, can't you see, why can't you, why can't you see  \\n It's all in me, yeah \\n Backing vocals \\n Turn off the light, turn off the light \\n Till' you see all my dreams \\n Lead vocals \\n All in me, yeah \\n Where is your logic  \\n Who do you need \\n Where can you turn in your delicate time of need \\n Follow me, follow me down, down, down, down \\n I do not need I do not need nobody \\n Follow me down, follow me down, down, down \\n Follow me, follow me, follow me down, down, down, down \\n See all my dreams, see all my dreams \\n Where is your logic \\n Where can turn \\n \""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with codecs.open(file,'r','utf-8') as f:\n",
    "    file_contents = \"\".join( f.read() )\n",
    "f.close()\n",
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
